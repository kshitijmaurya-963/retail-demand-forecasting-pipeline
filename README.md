Retail Demand Forecasting Micro-Pipeline (Classical + ML)
ğŸ“Œ Project Overview

This project builds a small, end-to-end forecasting pipeline for weekly retail demand.
Itâ€™s designed to feel like a realistic portfolio project: modular, reproducible, and insightful â€” but not overly perfect.

We simulate a dataset of 3 stores Ã— 5 SKUs (~27 months of daily sales) and aggregate to weekly demand.
The pipeline benchmarks classical methods (Naive, Seasonal Naive, SARIMAX) against a machine learning model (LightGBM).

The goal is:

Data ingestion & preprocessing

Feature engineering (calendar, holidays, lags, moving averages)

Model comparisons

Rolling-origin backtesting

Error analysis & visualization

Forecast generation for future periods

ğŸ” Why This Approach?

Classical baselines first â†’ to ground expectations (Naive, Seasonal Naive).

SARIMAX â†’ interpretable seasonal model, but not heavily tuned (realistic tradeoff).

LightGBM â†’ handles nonlinear interactions & engineered features better than pure time series models.

Rolling-origin backtest â†’ mimics real deployment (retraining & predicting in steps).

Plots + metrics â†’ numbers give precision, plots give intuition.

This mirrors how a DS would balance rigor with pragmatism.

âš™ï¸ Project Structure
retail_demand_forecasting_micro_pipeline/
â”‚
â”œâ”€â”€ data/                 <- synthetic sales data (CSV)
â”œâ”€â”€ reports/              <- metrics & plots after runs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py           <- data generation & ingestion
â”‚   â”œâ”€â”€ features.py       <- feature engineering
â”‚   â”œâ”€â”€ models.py         <- forecasting models
â”‚   â”œâ”€â”€ backtest.py       <- rolling-origin evaluation
â”‚   â”œâ”€â”€ forecast.py       <- final forecast generation
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA.ipynb         <- quick exploratory notebook
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile              <- run backtest/forecast easily
â””â”€â”€ README.md

ğŸš€ How to Run

Setup environment

python -m venv .venv
source .venv/bin/activate     # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt


Run backtest

make backtest


Outputs metrics CSV in reports/

Saves error & forecast plots

Run forecast

make forecast


Generates 4-week ahead forecasts

Saves plots per store-SKU

ğŸ“Š Example Outputs

Metrics (MAE, MAPE) per model

Forecast Plots

Naive vs SARIMAX vs LightGBM

Error distributions

(You can add screenshots here after running locally and saving plots.)

âœ… Key Learnings

Baselines are critical: Naive methods often surprisingly competitive.

SARIMAX can struggle with multiple SKUs/stores due to tuning complexity.

LightGBM with engineered features often generalizes better across series.

Rolling-origin evaluation avoids â€œdata leakageâ€ optimism.

ğŸ”® Future Improvements

Hyperparameter tuning (Bayesian optimization / Optuna).

More advanced ML/DL (XGBoost, CatBoost, RNNs, Transformers).

Incorporate price & promotions as external regressors.

Deploy forecasts via REST API or Streamlit dashboard.

ğŸ‘¤ Author

Project built as a portfolio case study to demonstrate end-to-end data science workflow:
from idea â†’ pipeline â†’ models â†’ evaluation â†’ storytelling.